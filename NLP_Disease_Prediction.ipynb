{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlxspEABevMdks178pBY1Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kshitijsharma37/Capstone-Navigation-Robot/blob/main/NLP_Disease_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTK9lcIkkPXf"
      },
      "outputs": [],
      "source": [
        "pip install mtranslate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "!pip install pyaudio\n",
        "!pip3 install google-cloud-speech\n",
        "!pip3 install SpeechRecognition"
      ],
      "metadata": {
        "id": "YOLei9p2JZax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all imports\n",
        "from io import BytesIO\n",
        "from base64 import b64decode\n",
        "from google.colab import output\n",
        "from IPython.display import Javascript\n",
        "\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record(sec=3):\n",
        "  print(\"Speak Now...\")\n",
        "  display(Javascript(RECORD))\n",
        "  sec += 1\n",
        "  s = output.eval_js('record(%d)' % (sec*1000))\n",
        "  print(\"Done Recording !\")\n",
        "  b = b64decode(s.split(',')[1])\n",
        "  return b #byte stream"
      ],
      "metadata": {
        "id": "PZF3vOReJbmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio = record()"
      ],
      "metadata": {
        "id": "FXAx63A4JeFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "# convert the byte stream to an instance of AudioData\n",
        "audio_data = sr.AudioData(audio, sample_rate=44100, sample_width=2)\n",
        "\n",
        "# recognize speech using Google Speech Recognition\n",
        "r = sr.Recognizer()\n",
        "try:\n",
        "    text = r.recognize_google(audio_data)\n",
        "    print(\"Google Speech Recognition thinks you said \" + text)\n",
        "except sr.UnknownValueError:\n",
        "    print(\"Google Speech Recognition could not understand audio\")\n",
        "except sr.RequestError as e:\n",
        "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))"
      ],
      "metadata": {
        "id": "-riMzdW2JgPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mtranslate import translate\n"
      ],
      "metadata": {
        "id": "VkyqX9XgkexD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"ನನಗೆ ಶೀತ ಮತ್ತು ಕೆಮ್ಮು ಇದೆ ಮತ್ತು ನಾನು ಸಾಯಲು ಬಯಸುತ್ತೇನೆ. ನನಗೆ ಜ್ವರ ಇರಬಹುದು ಎಂದು ನಾನು ಭಾವಿಸುತ್ತೇನೆ. ನೀನು ಇನ್ನೂ ಇದ್ದೀಯಾ? ಕೇಳು, ದಯವಿಟ್ಟು ನನ್ನನ್ನು ಗುಣಪಡಿಸು.\"\n",
        "translated_text = translate(text, 'en')\n",
        "\n",
        "print(\"Kannada text: \" + text)\n",
        "print(\"Translated text: \" + translated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN5TSI_Vkgv1",
        "outputId": "950f40ed-86db-4fb3-fa27-e55e3e9d3164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kannada text: ನನಗೆ ಶೀತ ಮತ್ತು ಕೆಮ್ಮು ಇದೆ ಮತ್ತು ನಾನು ಸಾಯಲು ಬಯಸುತ್ತೇನೆ. ನನಗೆ ಜ್ವರ ಇರಬಹುದು ಎಂದು ನಾನು ಭಾವಿಸುತ್ತೇನೆ. ನೀನು ಇನ್ನೂ ಇದ್ದೀಯಾ? ಕೇಳು, ದಯವಿಟ್ಟು ನನ್ನನ್ನು ಗುಣಪಡಿಸು.\n",
            "Translated text: I have a cold and a cough and I want to die. I think I might have the flu. are you still there Hear, please heal me.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import mode\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "KRqIAqwcnHLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the train.csv by removing the\n",
        "# last column since it's an empty column\n",
        "DATA_PATH = \"/content/sample_data/dataset/Training.csv\"\n",
        "data = pd.read_csv(DATA_PATH).dropna(axis = 1)\n",
        "\n",
        "# Checking whether the dataset is balanced or not\n",
        "disease_counts = data[\"prognosis\"].value_counts()\n",
        "temp_df = pd.DataFrame({\n",
        "\t\"Disease\": disease_counts.index,\n",
        "\t\"Counts\": disease_counts.values\n",
        "})\n",
        "\n",
        "plt.figure(figsize = (18,8))\n",
        "sns.barplot(x = \"Disease\", y = \"Counts\", data = temp_df)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "on-HRHIaIVJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding the target value into numerical\n",
        "# value using LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "data[\"prognosis\"] = encoder.fit_transform(data[\"prognosis\"])"
      ],
      "metadata": {
        "id": "18-Z1-CyJmKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:,:-1]\n",
        "y = data.iloc[:, -1]\n",
        "X_train, X_test, y_train, y_test =train_test_split(\n",
        "X, y, test_size = 0.2, random_state = 24)\n",
        "\n",
        "print(f\"Train: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Test: {X_test.shape}, {y_test.shape}\")"
      ],
      "metadata": {
        "id": "XWcYrDBGJp3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining scoring metric for k-fold cross validation\n",
        "def cv_scoring(estimator, X, y):\n",
        "\treturn accuracy_score(y, estimator.predict(X))\n",
        "\n",
        "# Initializing Models\n",
        "models = {\n",
        "\t\"SVC\":SVC(),\n",
        "\t\"Gaussian NB\":GaussianNB(),\n",
        "\t\"Random Forest\":RandomForestClassifier(random_state=18)\n",
        "}\n",
        "\n",
        "# Producing cross validation score for the models\n",
        "for model_name in models:\n",
        "\tmodel = models[model_name]\n",
        "\tscores = cross_val_score(model, X, y, cv = 10,\n",
        "\t\t\t\t\t\t\tn_jobs = -1,\n",
        "\t\t\t\t\t\t\tscoring = cv_scoring)\n",
        "\tprint(\"==\"*30)\n",
        "\tprint(model_name)\n",
        "\tprint(f\"Scores: {scores}\")\n",
        "\tprint(f\"Mean Score: {np.mean(scores)}\")"
      ],
      "metadata": {
        "id": "1h161hvSJuQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and testing SVM Classifier\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "preds = svm_model.predict(X_test)\n",
        "\n",
        "print(f\"Accuracy on train data by SVM Classifier\\\n",
        ": {accuracy_score(y_train, svm_model.predict(X_train))*100}\")\n",
        "\n",
        "print(f\"Accuracy on test data by SVM Classifier\\\n",
        ": {accuracy_score(y_test, preds)*100}\")\n",
        "cf_matrix = confusion_matrix(y_test, preds)\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(cf_matrix, annot=True)\n",
        "plt.title(\"Confusion Matrix for SVM Classifier on Test Data\")\n",
        "plt.show()\n",
        "\n",
        "# Training and testing Naive Bayes Classifier\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "preds = nb_model.predict(X_test)\n",
        "print(f\"Accuracy on train data by Naive Bayes Classifier\\\n",
        ": {accuracy_score(y_train, nb_model.predict(X_train))*100}\")\n",
        "\n",
        "print(f\"Accuracy on test data by Naive Bayes Classifier\\\n",
        ": {accuracy_score(y_test, preds)*100}\")\n",
        "cf_matrix = confusion_matrix(y_test, preds)\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(cf_matrix, annot=True)\n",
        "plt.title(\"Confusion Matrix for Naive Bayes Classifier on Test Data\")\n",
        "plt.show()\n",
        "\n",
        "# Training and testing Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(random_state=18)\n",
        "rf_model.fit(X_train, y_train)\n",
        "preds = rf_model.predict(X_test)\n",
        "print(f\"Accuracy on train data by Random Forest Classifier\\\n",
        ": {accuracy_score(y_train, rf_model.predict(X_train))*100}\")\n",
        "\n",
        "print(f\"Accuracy on test data by Random Forest Classifier\\\n",
        ": {accuracy_score(y_test, preds)*100}\")\n",
        "\n",
        "cf_matrix = confusion_matrix(y_test, preds)\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(cf_matrix, annot=True)\n",
        "plt.title(\"Confusion Matrix for Random Forest Classifier on Test Data\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YK7qAiQmJ5a_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the models on whole data\n",
        "final_svm_model = SVC()\n",
        "final_nb_model = GaussianNB()\n",
        "final_rf_model = RandomForestClassifier(random_state=18)\n",
        "final_svm_model.fit(X, y)\n",
        "final_nb_model.fit(X, y)\n",
        "final_rf_model.fit(X, y)\n",
        "\n",
        "# Reading the test data\n",
        "test_data = pd.read_csv(\"/content/sample_data/dataset/Testing.csv\").dropna(axis=1)\n",
        "\n",
        "test_X = test_data.iloc[:, :-1]\n",
        "test_Y = encoder.transform(test_data.iloc[:, -1])\n",
        "\n",
        "# Making prediction by take mode of predictions\n",
        "# made by all the classifiers\n",
        "svm_preds = final_svm_model.predict(test_X)\n",
        "nb_preds = final_nb_model.predict(test_X)\n",
        "rf_preds = final_rf_model.predict(test_X)\n",
        "\n",
        "final_preds = [mode([i,j,k])[0][0] for i,j,\n",
        "\t\t\tk in zip(svm_preds, nb_preds, rf_preds)]\n",
        "\n",
        "print(f\"Accuracy on Test dataset by the combined model\\\n",
        ": {accuracy_score(test_Y, final_preds)*100}\")\n",
        "\n",
        "cf_matrix = confusion_matrix(test_Y, final_preds)\n",
        "plt.figure(figsize=(12,8))\n",
        "\n",
        "sns.heatmap(cf_matrix, annot = True)\n",
        "plt.title(\"Confusion Matrix for Combined Model on Test Dataset\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bxOtZuD3J_gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symptoms = X.columns.values\n",
        "\n",
        "# Creating a symptom index dictionary to encode the\n",
        "# input symptoms into numerical form\n",
        "symptom_index = {}\n",
        "for index, value in enumerate(symptoms):\n",
        "\tsymptom = \" \".join([i.capitalize() for i in value.split(\"_\")])\n",
        "\tsymptom_index[symptom] = index\n",
        "\n",
        "data_dict = {\n",
        "\t\"symptom_index\":symptom_index,\n",
        "\t\"predictions_classes\":encoder.classes_\n",
        "}\n",
        "print(data_dict)\n",
        "\n",
        "# Defining the Function\n",
        "# Input: string containing symptoms separated by commas\n",
        "# Output: Generated predictions by models\n",
        "def predictDisease(symptoms):\n",
        "\tsymptoms = symptoms.split(\",\")\n",
        "\t\n",
        "\t# creating input data for the models\n",
        "\tinput_data = [0] * len(data_dict[\"symptom_index\"])\n",
        "\tfor symptom in symptoms:\n",
        "\t\tindex = data_dict[\"symptom_index\"][symptom]\n",
        "\t\tinput_data[index] = 1\n",
        "\t\t\n",
        "\t# reshaping the input data and converting it\n",
        "\t# into suitable format for model predictions\n",
        "\tinput_data = np.array(input_data).reshape(1,-1)\n",
        "\t\n",
        "\t# generating individual outputs\n",
        "\trf_prediction = data_dict[\"predictions_classes\"][final_rf_model.predict(input_data)[0]]\n",
        "\tnb_prediction = data_dict[\"predictions_classes\"][final_nb_model.predict(input_data)[0]]\n",
        "\tsvm_prediction = data_dict[\"predictions_classes\"][final_svm_model.predict(input_data)[0]]\n",
        "\t\n",
        "\t# making final prediction by taking mode of all predictions\n",
        "\tfinal_prediction = mode([rf_prediction, nb_prediction, svm_prediction])[0][0]\n",
        "\tpredictions = {\n",
        "\t\t\"rf_model_prediction\": rf_prediction,\n",
        "\t\t\"naive_bayes_prediction\": nb_prediction,\n",
        "\t\t\"svm_model_prediction\": svm_prediction,\n",
        "\t\t\"final_prediction\":final_prediction\n",
        "\t}\n",
        "\treturn predictions\n",
        "\n",
        "# Testing the function\n",
        "#print(predictDisease(\"Depression\"))"
      ],
      "metadata": {
        "id": "9xt_KeB7KQE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk import RegexpTokenizer\n",
        "from nltk import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import difflib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8P6mXUcrJCA",
        "outputId": "57ec9321-a4ef-4421-ec58-49569d300b0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_extractor(sentence):\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens =tokenizer.tokenize(sentence)\n",
        "    tokens=[token.lower() for token in tokens]\n",
        "    tokens = [token for token in tokens if not token in stopwords.words()]\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "Tp0GEIFxrh-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def symptoms(symptoms):\n",
        "    final_symptoms = []\n",
        "    final_symptoms_flat = []\n",
        "    df_train = pd.read_csv('/content/sample_data/dataset/Training.csv', delimiter=',')\n",
        "    vocab = df_train.columns.tolist()\n",
        "\n",
        "    for symptom in symptoms:\n",
        "        final_symptoms.append(difflib.get_close_matches(symptom, vocab, cutoff=0.6))\n",
        "    for sublist in final_symptoms:\n",
        "        for item in sublist:\n",
        "            final_symptoms_flat.append(item)\n",
        "\n",
        "    return set(final_symptoms_flat)"
      ],
      "metadata": {
        "id": "IGDPnaD_rnWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "description = translated_text"
      ],
      "metadata": {
        "id": "E1vcHgvGruP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_symptoms = symptoms(word_extractor(description))\n",
        "print(final_symptoms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozTaB0dkrxBR",
        "outputId": "4f02633c-d802-4e06-e028-59090a342dfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cough'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final_symptoms = {'cramps', 'mild_fever', 'skin_rash', 'high_fever'}\n",
        "final_symptoms = list(final_symptoms)\n",
        "for i in range(len(final_symptoms)):\n",
        "  \n",
        "  print(final_symptoms[i])\n",
        "  final_symptoms[i] = final_symptoms[i].capitalize()\n",
        "  for j in range(len(final_symptoms[i])):\n",
        "    \n",
        "    if final_symptoms[i][j] == '_':\n",
        "      final_symptoms[i] = final_symptoms[i][:j] + ' ' + final_symptoms[i][j+1].upper() + final_symptoms[i][j+2:]\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phji9Tonsur-",
        "outputId": "fade373f-0c1c-43f0-8e53-1c31a936c2b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cough\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final = ','.join(final_symptoms)\n",
        "print(final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmvVhevBu8nP",
        "outputId": "488d7df6-1423-463c-8243-363ed687fcf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cough\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  predictDisease(final)\n",
        "except:\n",
        "  print('Dear Patient, please try to describe your symptoms in a more concise way. That will help the system recognise the disease easily.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQI_stk8vpdZ",
        "outputId": "552960f2-2f0b-47da-b797-0ff7355749f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
            "  warnings.warn(\n",
            "<ipython-input-64-630e89ea0956>:38: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  final_prediction = mode([rf_prediction, nb_prediction, svm_prediction])[0][0]\n",
            "<ipython-input-64-630e89ea0956>:38: DeprecationWarning: Support for non-numeric arrays has been deprecated as of SciPy 1.9.0 and will be removed in 1.11.0. `pandas.DataFrame.mode` can be used instead, see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html.\n",
            "  final_prediction = mode([rf_prediction, nb_prediction, svm_prediction])[0][0]\n"
          ]
        }
      ]
    }
  ]
}